# General Settings
# ----------------
log_file: "autoencoder_training.log" # Log file name for this training run
num_workers: 0                       # Number of workers for DataLoader (0 for main process)
force_cpu: false                     # Set to true to force CPU usage, even if CUDA is available
cuda_device: 0                       # GPU index to use if CUDA is available and force_cpu is false

# Data Input Configuration
# ------------------------
data:
  json_path: "../../../my_protein.json" # Path to the multi-frame coordinate data (JSON format)
  pdb_path: "heavy_chain.pdb"           # Path to a reference PDB file for atom indexing and topology

# Graph Construction Settings
# ---------------------------
graph:
  knn_value: 4                          # Number of K nearest neighbors for graph construction per frame

# HNO Encoder Configuration (Graph Autoencoder - Encoder Part)
# ----------------------------------------------------------
hno_encoder:
  hidden_dim: 8                         # Hidden dimension for HNO GNN layers
  cheb_order: 4                         # Chebyshev polynomial order for ChebConv layers
  num_epochs: 4000                      # Number of training epochs for the HNO encoder
  learning_rate: 0.0001                 # Learning rate for HNO training
  batch_size: 16                        # Batch size for HNO training
  save_interval: 500                    # Save encoder checkpoint every N epochs

# Decoder2 Training Configuration (Graph Autoencoder - Decoder Part)
# ----------------------------------------------------------------
decoder2:
  num_epochs: 10                        # Number of training epochs for Decoder2
  learning_rate: 0.0003                 # Learning rate for Decoder2 training
  batch_size: 16                        # Batch size for Decoder2 training
  base_loss_weight: 1.0                 # Multiplier for the base coordinate MSE loss
  save_interval: 500                    # Save decoder checkpoint every N epochs

# Decoder2 Architecture Settings
# ------------------------------
decoder2_settings:
  conditioner_mode: "z_ref"             # Conditioner type: 'X_ref' (reference coordinates) or 'z_ref' (reference embedding)
  pooling_type: "blind"                 # Pooling strategy: 'blind' (global) or 'residue' (per-residue)
  output_height: 50                     # Target height for AdaptiveAvgPool2d in primary pooling (for blind/residue)
  output_width: 2                       # Target width for AdaptiveAvgPool2d in primary pooling
  mlp_hidden_dim: 128                   # Hidden dimension for the Decoder2 MLP layers
  num_hidden_layers: 12                 # Number of layers in the final Decoder2 MLP (includes input and output layers)

  # Optional advanced features for pooling (primarily if pooling_type != 'blind' or for future extensions)
  use_second_level_pooling: false       # Enable pooling across segment embeddings (e.g., for residue pooling)
  output_height2: 100                   # Target height for secondary pooling (if enabled)
  output_width2: 20                     # Target width for secondary pooling (if enabled)
  # Cross-attention is not fully implemented in the provided ProteinStateReconstructor2D
  use_cross_attention: false            # Enable cross-attention mechanism
  cross_attention_type: "global"        # Type of cross-attention ('global', 'residue')

# Dihedral Loss Configuration (Optional for Decoder2 Training)
# ------------------------------------------------------------
dihedral_loss:
  use_dihedral_loss: true               # Set true to enable dihedral loss during Decoder2 fine-tuning, false to disable
  torsion_info_path: "condensed_residues.json" # Path to JSON defining dihedral atoms/indices per residue
  lambda_divergence: 0.1                # Weight for the dihedral distribution divergence term (KL/JS/Wasserstein)
  lambda_torsion_mse: 1.0               # Weight for the direct torsion angle MSE term
  divergence_type: "JS"                 # Type of divergence: "KL", "JS", or "WASSERSTEIN"
  fraction_dihedral: 0.1                # Apply dihedral loss to this fraction of training batches (0.0 to 1.0)

# Output Directories Configuration
# --------------------------------
output_directories:
  checkpoint_dir: "checkpoints"         # Directory for saving model checkpoints
  structure_dir: "structures"           # Directory for coordinate outputs (.h5, .pt)
  latent_dir: "latent_reps"             # Directory for embedding/latent representation outputs (.h5, .pt)
