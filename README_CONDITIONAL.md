# Conditional Protein Conformation Generation Pipeline

This document describes an advanced deep learning pipeline for training a *conditional* generative model. Unlike a standard generative model, this pipeline can be guided by a novel, unseen protein structure to generate new 3D conformations that are consistent with that specific structural template.

The workflow is divided into two main phases:
1.  **Training Phase:** Learn the fundamental relationships between protein structures and their dynamic conformations using a dataset of known proteins and their structural variants.
2.  **Inference Phase:** Use the trained models to generate new conformations for a new, unseen protein structure provided by the user.

## Core Components

This pipeline uses a set of specialized scripts and configuration files.

### Training Scripts
-   **`chebnet_conditional_setup.py`**: The main script for training the foundational autoencoder (HNO Encoder and Decoder). It processes multiple protein systems and their artificially generated structural variants to create a rich training dataset.
    -   **Config:** `param_conditional.yaml`
-   **`conditional_diffusion.py`**: Trains the core generative model. It's a conditional diffusion model that learns how a specific structural signature (`z_ref`) influences the distribution of dynamic conformations (`pooled_embeddings`).
    -   **Config:** `param_conditional_diffusion.yaml`

### Inference Scripts
-   **`generate_from_new_pdb.py`**: The first step of the inference pipeline. It takes a new PDB file, uses the pre-trained HNO Encoder to calculate its unique `z_ref` conditioner, and then uses the pre-trained diffusion model to generate a set of corresponding latent embeddings.
    -   **Config:** `param_generate_from_new.yaml`
-   **`decode_novel_latents.py`**: The second inference step. It takes the latent embeddings generated by the previous script and uses the pre-trained Decoder to translate them back into full 3D atom coordinates.
    -   **Config:** `param_decode_novel.yaml`
-   **`h5_to_pdb_novel.py`**: The final utility script. It converts the generated 3D coordinates from the HDF5 format into standard PDB files for visualization.
    -   **Config:** No YAML file; configured via command-line arguments.

## Workflow: How to Run the Pipeline

Follow these steps in order. Ensure all paths and model parameters in the YAML files are correctly configured before running each script.

---

### Phase 1: Training the Generative Models

This phase only needs to be done once to train the models.

**Step 1: Train the Foundational Autoencoder**
This script trains the HNO Encoder and the Decoder on your dataset of protein systems.
```bash
python chebnet_conditional_setup.py --config param_conditional.yaml
```
-   **Key Outputs:**
    -   `checkpoints/hno_checkpoint.pth` (Trained Encoder)
    -   `checkpoints/decoder2_checkpoint.pth` (Trained Decoder)
    -   `latent_reps/reference_conditioners.h5` (All `z_ref` conditioners)
    -   `latent_reps/pooled_embeddings.h5` (All dynamic embeddings)

**Step 2: Train the Conditional Diffusion Model**
This script uses the data from Step 1 to train the generative model. It learns the mapping from a `z_ref` to its corresponding conformations.
```bash
python conditional_diffusion.py --config param_conditional_diffusion.yaml
```
-   **Key Output:**
    -   `conditional_diffusion_output/checkpoints/cond_diffusion_latest.pth` (Trained Diffusion Model)

---

### Phase 2: Inference - Generating Conformations for a New PDB

Once the models are trained, you can repeat this phase for any new PDB file you want to analyze.

**Step 3: Generate Latent Embeddings for the New PDB**
Provide your new PDB file. This script will generate the latent embeddings for it.
```bash
python generate_from_new_pdb.py \
    --config param_generate_from_new.yaml \
    --pdb /path/to/your/new_protein.pdb \
    --output novel_protein_latents.h5
```
-   **Key Output:**
    -   `novel_protein_latents.h5`: An HDF5 file containing the `novel_z_ref_conditioner` and the `generated_pooled_embeddings`.

**Step 4: Decode Latent Embeddings into 3D Coordinates**
This script converts the latent embeddings from Step 3 into physical coordinates.
```bash
python decode_novel_latents.py \
    --config param_decode_novel.yaml \
    --input novel_protein_latents.h5 \
    --output final_coords_for_novel_protein.h5
```
-   **Key Output:**
    -   `final_coords_for_novel_protein.h5`: An HDF5 file containing the final `generated_coords`.

**Step 5: Convert Final Coordinates to PDB Files**
The final step. This script creates the viewable PDB files from the coordinate data.
```bash
python h5_to_pdb_novel.py \
    --input final_coords_for_novel_protein.h5 \
    --template_pdb /path/to/your/new_protein.pdb \
    --output_dir generated_pdbs_for_novel_protein/ \
    --max_frames 50
```
-   **Key Output:**
    -   `generated_pdbs_for_novel_protein/`: A directory containing the final PDB files (e.g., `generated_novel_frame_1.pdb`, etc.).
